{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SYS6016 Midterm Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rohan Bapat and Jack Prominski\n",
    "\n",
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from gensim.models.doc2vec import TaggedDocument, TaggedLineDocument, LabeledSentence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>clean_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh baby, how you doing?\\nYou know I'm gonna cu...</td>\n",
       "      <td>oh babi know gon na cut right chase women made...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>playin' everything so easy,\\nit's like you see...</td>\n",
       "      <td>playin everyth easi like seem sure still way d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
       "      <td>search tender hard find love need live look tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...</td>\n",
       "      <td>oh oh oh oh oh oh vers wrote book stand titl b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>black-culture</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Party the people, the people the party it's po...</td>\n",
       "      <td>parti peopl peopl parti pop sit around see loo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              song  year           artist genre  \\\n",
       "0        ego-remix  2009  beyonce-knowles   Pop   \n",
       "1     then-tell-me  2009  beyonce-knowles   Pop   \n",
       "2          honesty  2009  beyonce-knowles   Pop   \n",
       "3  you-are-my-rock  2009  beyonce-knowles   Pop   \n",
       "4    black-culture  2009  beyonce-knowles   Pop   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  Oh baby, how you doing?\\nYou know I'm gonna cu...   \n",
       "1  playin' everything so easy,\\nit's like you see...   \n",
       "2  If you search\\nFor tenderness\\nIt isn't hard t...   \n",
       "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...   \n",
       "4  Party the people, the people the party it's po...   \n",
       "\n",
       "                                        clean_lyrics  \n",
       "0  oh babi know gon na cut right chase women made...  \n",
       "1  playin everyth easi like seem sure still way d...  \n",
       "2  search tender hard find love need live look tr...  \n",
       "3  oh oh oh oh oh oh vers wrote book stand titl b...  \n",
       "4  parti peopl peopl parti pop sit around see loo...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "df = pd.read_csv('clean_lyrics_all.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with missing data -- drop obs with missing lyrics and unknown/other genre\n",
    "df = df.dropna()\n",
    "df = df[(df.genre != 'Other') & (df.genre != 'Not Available')]\n",
    "\n",
    "# create label -- unique id for each song\n",
    "df['label'] = df['artist'].map(str) + df['song']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample the dataset\n",
    "\n",
    "genres = list(set(df.genre))\n",
    "subdfs = []\n",
    "nobs = df.groupby('genre')['genre'].count()\n",
    "\n",
    "for genre in genres:\n",
    "    if nobs[nobs.index == genre].values[0] > 10000:\n",
    "        arr = np.array(df.index[df.genre == genre])\n",
    "        samp = list(np.random.choice(arr, 10000, replace=False))\n",
    "        subdfs.append(df.loc[df.index.isin(samp)])\n",
    "    else:\n",
    "        subdfs.append(df[df.genre == genre])\n",
    "\n",
    "subdf = pd.concat(subdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logit w/ TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>clean_lyrics</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>358</td>\n",
       "      <td>white-trash</td>\n",
       "      <td>2004</td>\n",
       "      <td>borialis</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Where should I begin cripplin' all you villain...</td>\n",
       "      <td>begin cripplin villain never injur civilian in...</td>\n",
       "      <td>borialiswhite-trash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>359</td>\n",
       "      <td>don-t-mean-a-thing</td>\n",
       "      <td>2004</td>\n",
       "      <td>borialis</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Enough of all that, let's switch up the format...</td>\n",
       "      <td>enough let switch format talk trash get bore f...</td>\n",
       "      <td>borialisdon-t-mean-a-thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>382</td>\n",
       "      <td>surefire</td>\n",
       "      <td>2007</td>\n",
       "      <td>brightwood</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Looking back, no turning back.\\nWouldn't take ...</td>\n",
       "      <td>look back turn back would take back second uns...</td>\n",
       "      <td>brightwoodsurefire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>383</td>\n",
       "      <td>taken</td>\n",
       "      <td>2007</td>\n",
       "      <td>brightwood</td>\n",
       "      <td>Rock</td>\n",
       "      <td>I am taken\\nI am not my own\\nI am floating\\nTe...</td>\n",
       "      <td>taken float teach fli solomon wait sing hi son...</td>\n",
       "      <td>brightwoodtaken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>599</td>\n",
       "      <td>red-threat</td>\n",
       "      <td>2007</td>\n",
       "      <td>fang</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Charles Manson is god, he was a crazy sod\\nHe ...</td>\n",
       "      <td>charl manson god wa crazi sod went deep end ki...</td>\n",
       "      <td>fangred-threat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                song  year      artist genre  \\\n",
       "0    358         white-trash  2004    borialis  Rock   \n",
       "1    359  don-t-mean-a-thing  2004    borialis  Rock   \n",
       "2    382            surefire  2007  brightwood  Rock   \n",
       "3    383               taken  2007  brightwood  Rock   \n",
       "4    599          red-threat  2007        fang  Rock   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  Where should I begin cripplin' all you villain...   \n",
       "1  Enough of all that, let's switch up the format...   \n",
       "2  Looking back, no turning back.\\nWouldn't take ...   \n",
       "3  I am taken\\nI am not my own\\nI am floating\\nTe...   \n",
       "4  Charles Manson is god, he was a crazy sod\\nHe ...   \n",
       "\n",
       "                                        clean_lyrics  \\\n",
       "0  begin cripplin villain never injur civilian in...   \n",
       "1  enough let switch format talk trash get bore f...   \n",
       "2  look back turn back would take back second uns...   \n",
       "3  taken float teach fli solomon wait sing hi son...   \n",
       "4  charl manson god wa crazi sod went deep end ki...   \n",
       "\n",
       "                        label  \n",
       "0         borialiswhite-trash  \n",
       "1  borialisdon-t-mean-a-thing  \n",
       "2          brightwoodsurefire  \n",
       "3             brightwoodtaken  \n",
       "4              fangred-threat  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf = subdf.reset_index()\n",
    "subdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv_fit=cv.fit_transform(subdf.clean_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Vocabulary\n",
    "tf_matrix_word = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word frequency for each word in vocabulary\n",
    "tf_matrix_freq = cv_fit.sum(axis = 0)\n",
    "tf_matrix_freq = np.array(tf_matrix_freq).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df with words and frequencies\n",
    "tf_df = pd.DataFrame({'word':tf_matrix_word, 'freq':tf_matrix_freq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the words in tf_df by word frequency in descending order\n",
    "tf_df.sort_values(by='freq',ascending=False, inplace=True)\n",
    "\n",
    "# The index column will be used will be used to remove head and tail words\n",
    "tf_df.reset_index(inplace=True)\n",
    "\n",
    "# The level_0 column will be used to assign rank to the word frequency, words with highest frequency\n",
    "# get top rank\n",
    "tf_df.reset_index(inplace=True)\n",
    "tf_df.rename(columns={'level_0':'rank'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get head words\n",
    "# Remove 20 words with highest frequency as head words\n",
    "head_word_count = 20\n",
    "head_words = list(tf_df['index'].head(head_word_count))\n",
    "\n",
    "# Get tail words\n",
    "# Remove 20 words with frequency less than 5 as tail words\n",
    "tail_word_freq = 5\n",
    "tail_words = list(tf_df.loc[tf_df['freq']<tail_word_freq,'index'])\n",
    "\n",
    "# Combine head and tail words\n",
    "head_words.extend(tail_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform BOW to TFIDF\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "tfidf = tfidf_vectorizer.fit_transform(subdf.clean_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for to remove head and tail words\n",
    "keep_words = list(set(np.arange(tfidf.shape[1])) - set(head_words))\n",
    "X = tfidf[:,keep_words]\n",
    "y = subdf[['genre']].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing sets\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59766, 37599)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<59766x37599 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3581292 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression model\n",
    "t0 = time()\n",
    "m_logclf = LogisticRegression(multi_class='multinomial',solver='sag', n_jobs=7)\n",
    "m_logclf.fit(X_train_tfidf, y_train)\n",
    "print(\"--- %s seconds ---\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48581180564850757"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "preds = m_logclf.predict(X_test_tfidf)\n",
    "y_test_resh = y_test.reshape((1, -1))\n",
    "y_list = list(y_test_resh[0])\n",
    "sum(np.equal(preds,np.array(y_list)))/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Country       0.64      0.52      0.58      2568\n",
      " Electronic       0.37      0.34      0.35      1739\n",
      "       Folk       0.13      0.74      0.23        81\n",
      "    Hip-Hop       0.79      0.78      0.78      1992\n",
      "      Indie       0.05      0.27      0.09       119\n",
      "       Jazz       0.50      0.50      0.50      1633\n",
      "      Metal       0.72      0.63      0.67      2256\n",
      "        Pop       0.39      0.34      0.37      2288\n",
      "        R&B       0.10      0.50      0.17       139\n",
      "       Rock       0.30      0.28      0.29      2127\n",
      "\n",
      "avg / total       0.53      0.49      0.50     14942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "print(classification_report(preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logit w/ Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of words (x), genres (y), and labels\n",
    "labels = subdf['label'].tolist()\n",
    "genre = subdf['genre'].tolist()\n",
    "words = subdf['clean_lyrics'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write words out to text file, one per line\n",
    "file = open('d2v_docs_2.txt', 'w')\n",
    "for doc in words:\n",
    "    file.write(\"%s\\n\" % doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate TaggedLineDocuments to feed into Doc2Vec\n",
    "docs = [doc for doc in TaggedLineDocument('d2v_docs_2.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Doc2Vec model\n",
    "t0 = time()\n",
    "model = Doc2Vec(docs, size=200, window=5, min_count=5, workers=7, iter=20)\n",
    "print(\"--- %s seconds ---\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('model_200.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Doc2Vec.load('model_200.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get document vectors to pass to Logit\n",
    "vectors = []\n",
    "for i in range(0,74708):\n",
    "    vectors.append(model.docvecs[i])\n",
    "vectors = np.asarray(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74708, 200)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify shape\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing sets\n",
    "X_train_d2v, X_test_d2v, y_train_d2v, y_test_d2v = train_test_split(vectors, genre, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression model\n",
    "t0 = time()\n",
    "logclf = LogisticRegression(multi_class='multinomial',solver='sag', n_jobs=7)\n",
    "logclf.fit(X_train_d2v, y_train)\n",
    "print(\"--- %s seconds ---\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24153393120064248"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "preds = logclf.predict(X_test_d2v)\n",
    "y_test_resh = y_test.reshape((1, -1))\n",
    "y_list = list(y_test_resh[0])\n",
    "sum(np.equal(preds,np.array(y_list)))/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Country       0.31      0.22      0.26      2992\n",
      " Electronic       0.03      0.11      0.04       362\n",
      "       Folk       0.05      0.42      0.09        52\n",
      "    Hip-Hop       0.51      0.34      0.41      2964\n",
      "      Indie       0.00      0.00      0.00         5\n",
      "       Jazz       0.11      0.23      0.15       807\n",
      "      Metal       0.50      0.26      0.34      3913\n",
      "        Pop       0.19      0.18      0.18      2087\n",
      "        R&B       0.00      0.20      0.01        15\n",
      "       Rock       0.17      0.19      0.18      1745\n",
      "\n",
      "avg / total       0.35      0.24      0.28     14942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "print(classification_report(preds, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
